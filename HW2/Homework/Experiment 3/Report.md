#### **1.λ 的影响**

- **λ 较小**：GAE 更依赖近期奖励，方差低但可能欠拟合，学习速度慢。
- **λ 接近 1**：GAE 更考虑长期回报，方差高但探索能力强，可能更快收敛到高分。
- **λ=1**：等价于蒙特卡洛方法（无偏差但高方差），在 LunarLander 中可能导致训练不稳定。

#### **2. λ 的特殊值含义**

- **λ = 0**：
  对应 **纯时序差分（TD）**，仅使用单步奖励和基线值函数，偏差大但方差低。在 LunarLander 中可能导致策略保守，难以学到长期策略（如稳定降落）。
- **λ = 1**：
  对应 **蒙特卡洛（MC）**，使用完整轨迹的累计回报，无偏差但方差高。在 LunarLander 中可能因稀疏奖励（如成功降落才有高分）导致训练不稳定。